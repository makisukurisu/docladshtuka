Как можно было заметить ранее - lip sync - сложная и кропотливая работа актёров и аниматоров, однако и такой материал легко испортить ошибками как со стороны актёров, так и со стороны людей за озвучкой.

Поэтому возникла потребность в качественном lip sync-е с минимальными затратами для создателя, и при этом - высоким качеством материала.

Как и во многих других отраслях логичным становиться использование нейронных сетей для решения таких сложных заданий.

Так для решения проблем переводов может использоваться Wav2Lip подобная нейронная сеть, что анализирует как аудио, так и видео сингнал находит лицо говорящего человека и анализируя звук находит произносимые звуки, что имеют яркую артикуляцию.

Как можно заметить здесь, эту сеть можно использовать не только для переовда материалов на разные языки, но и для простой синхронизации звука с видео, если аудио сигнал имеет непостоянные высокие задержки. Или и вовсе - сигнал прерываеться, так как сеть на основе предыдущих кадров способна построить видео используя один лишь звук.

Таким образом, имея лицо, с распознанным ртом и расставленными моментами с возможными вариациями звуков, нейронная сеть принимает решение, какую артикуляцию выбрать на данный звук, что генерируеться во время анализа видео потока.

Основным отличием этой нейронной сети от всех последующих сетей, что указанны в этой работе - наличие нескольких нейронных сетей для одной общей цели, но двух разных задач.
Так основной задачей являеться распознование фонем и генерация лица, однако так же присутствует вторая сеть, которая анализирует и оценивает качество сгенерированного материала, как на наличие артефактов изображения, так и артефактов генерации речевого аппарата.
Эта же нейронная сеть показывает лучшие результаты на тестовых материалах, в разделах синхронизации и качества генерируемого материала. Результат становиться лучше, если второй сети, ответственной за оценивание материала предоставить больше кадров для оценки. Так LipGAN использует всего один кадр, и пусть это может сделать более точный во времени липсинк, на практике качество артикуляции играет большее значение для людей, если принять во внимание то что погрешности во времени не так уж и велики. Как показано в таблице 2.2.1 если увеличить кол-во кадров для анализа с 1 до 5, точность падает с 79 % до почти 92%, а остальные метрики становяться лучше примерно на треть.

Так же понятно, такая нейронная сеть применима только к тем работам, где говорящее лицо - человек.
Однако не всегда нужно переводить какое-то произведение или выступление, например, если во время обучения появиться необходимость показать историческую личность с её цитатой ранее бы пришлось рисовать лицо, или и вовсе - прилепить рисованые выбивающиеся губы к портрету личности, что портит общее ощущение важности цитаты и придаёт комичности.

С использованием LipGAN можно решить эту проблему, и ещё несколько других по пути. Так нейронная сеть LipGAN анализирует видео поток, который может быть и вовсе - статичной картинкой и звукуовую дорожку и на выходе даёт реалистичное видео с синхронизироваными движениями рта и звука. Так например можно "Оживить" Елизавету I и вручить ей её цитату на уроках истории.

Эта же технология по заявлению авторов позволит разработчикам игр создавать правдоподобные анимации лица для персонажей своих игр с множеством локализаций.

Однако, если вы автор собственных анимаций или стример что не хочет показывать своё лицо, то вам может помочь CharacterLipSync, эта нейронная сеть использует заранее нарисованные эмоции и звуки для создания видео потока в реальном времени. Может использоваться как с трекингом по лицу, так и без него. Как и во всех нейронных сетях выше - производиться анализ аудио-дорожки, однако видео сигнал здесь полностью генерируем без использования трекинга (что часто делаеться во время стримов), таким образом нейронная сеть не только анализирует аудио и подбирает необходимый сейчас рот для персонажа, но ещё и создаёт переход между каждой сменой, что вручную делать намного дольше, даже если бы все рты были расставлены сразу.

Таким образом эта нейронная сеть решает сразу несколько проблем, если её комбинировать с другими - проблему аниматоров, которым достаточно будет нарисовать базовые рты и предоставить нейронной сети аудиопоток с озвучкой персонажа, а также проблемы стримеров-анонимов, которым ранее требовалось дорогостоящее оборудование для распознавания мимики на лице и движения тела, теперь же, с использованием комбинации нейронных сетей можно делать такой видео поток в реальном времени пользуясь одной лишь веб-камерой и микрофоном.

Для этой нейронной сети использована LSTM модель (Long Short Time Memmory), что позволяет быстро обнаружить виземы, и требуемые артикуляции, после чего из списка артикуляций подбираються необходимые. Не смотря на видимую "Машинность" и не лучшие соответствия по липсинку (точность соответствия не более 70%), авторы учли некоторые "Привычки" аниматоров, так - новая артикуляция держиться на лице не менее двух кадров видео, так же один из персонажей был посвящён экспериментам с артистическими приёмами.

Одной из техник распознования фонем может быть использование вейвлет-преобразования, с применеием нейронных сетей для подбора коэффициентов. Используя данные преобразования можно найти границы фонем. Фонема - минимальная смыслоразличительная единица языка. Из библиотеки звуков можно подобрать фонему, а это так же - хорошая работа для нейронных сетей. Подбор порогового коэфициента изменяет то, насколько малая разница должна быть между звучанием для разграничения фонем. Так при малых значениях коэфициента некоторые близко расположенные звуки могут повторять предыдущие, или образовывать слитные фонемы. Поэтому правильный подбор коэфициента важен для качественного определения текущего звука, что позволит сделать липсинк качественнее.

Предложения и выводы: ?

Используя указанные выше методы в сочетании с, например, интерфейсом безмолвного доступа можно увеличить точность распознования фонем, что позволит увеличить как качество их размещения за счёт того что нейронная сеть будет тратить меньше времени на их поиск, так и качество визуальное за счёт освободившегося времени. Так же без использования ИБД, но пользуясь некоторыми особенностями организма, что были исследованы во время создания таких интерфейсов. Имея картинку должного качества можно анализировать смещения горла во время разговора, или, если есть такая возможность - анализировать перемещения языка и изменения формы рта. Последние два совета куда лучше применимы к людям озвучивающим записи, однако комбинация с ИБД позволит улучшить точность для всех сторон записи.

Также можно указать то, что при наличии более совершенного алгоритма машинного зрения и более точной калибровки оценивания для сети Wav2Lip, можно добиться лучших результатов по качеству генерации и более точную синхронизацию.
И поскольку в последнее время мирвые гиганты технологий как Nvidia, Samsung и другие создавали продукты с применением этой технологии, есть вероятность её улучшения в ближайшем будущем.